"getting you up to speed, we're going to be generating two categories of outputs. \n\n1. an XTP Schema, which is a YAML definition of functions that can be called by other code. The code is encapsulated in a WebAssembly module, but that isn't important to know to generate the XTP Schema. There are a couple helpful things to know about XTP Schema and I'll mention some files and references to aid you in this information (take special note of the xtp-schema.json file which contrains the types and specification of types and functions that can be defined in the schema --- DO NOT try to add anything new in your output schemas, follow the spec exactly. Use the example-schema as a point of reference about the required fields of a schema, only adding that and property field can be nullable if it isn't _required_ to do some computation. \n\nI'll also add a README and your own interpretation of that README so you can get an Idea of what we're doing and have already done. @README.md @README.inferred.md \n\nThis should all help you understand about how to generate an XTP Shema, and the input of this will come from some code calling a function like `generateSchema` which takes some parameters: \n\n (this is mentioned in the context)\n\nYour job is to take the parameters passed to something like generateSchema (which an LLM should come up with), and output an XTP Schema that describes the function (or functions) needed to actually use the code. That includes Inputs and Outputs to the function, which you would think of as an input/output struct ,, and some descriptive context about what the code should do. \n\n> NOTE: take special care _not_ to include the function signature / declaration\n> in any generated code you add to the `codeSamples` `source` field. It should\n> _only_ be the function body, since this is used to stub out example code in\n> the generated output provided to the end user.\n\nCode lookup & generation concept\n\nProvided a library function like:\n\n```js\nfunction generateSchema(\n  description: string,\n  inputDescription: string,\n  outputDescription: string,\n  additionalContext?: string\n): XTPSchema\n```\n\nThis brings us to the second kind of output.. which is \n\n2. the actual implementation of some code, that I will provide you with a stub for. Basically, with the generated XTP Schema, I will generate the stub code (partially filled in) for you to complete the implementation of. \n\nYou will be given code that was generated from the XTP Schema without the inside of the functions in the `main` file filled in. You must 1. learn about the code from looking at the generated code I provide like the libraries and types. And then generate code that should work uneditied to implement the functions. \n\nHere is an XTP Schem example: \n\n```yaml file=audio-analysis-schema.yaml\nversion: v1-draft\nexports:\n  findPeakFrequency:\n    description: |\n      Determine the frequency that has the highest amplitude, over this sample of audio data.\n      This function runs some kind of time-dimensional FFT on audio input.\n    codeSamples:\n      - lang: typescript\n        source: |\n          // Perform FFT and find peak frequency\n          const fftResult = performFFT(input);\n          const peakFrequency = findPeak(fftResult);\n          return { frequency: peakFrequency };\n    input:\n      contentType: application/x-binary\n      type: buffer\n      description: A stream of bytes including audio samples\n    output:\n      contentType: application/json\n      $ref: \"#/components/schemas/PeakFrequencyResponse\"\n\ncomponents:\n  schemas:\n    PeakFrequencyResponse:\n      description: Output from the findPeakFrequency function\n      properties:\n        frequency:\n          type: number\n          format: float\n          description: The frequency in Hz that has the highest amplitude\n\n    InferenceMLInput:\n      description: Input for the GPU-accelerated ML inference function\n      properties:\n        model:\n          type: string\n          description: The name or identifier of the ML model to use\n        data:\n          type: object\n          description: The input data for the ML model\n\n    InferenceMLOutput:\n      description: Output from the GPU-accelerated ML inference function\n      properties:\n        result:\n          type: object\n          description: The result of the ML inference\n\n    EmbeddingRequest:\n      description: Input for the text embedding function\n      properties:\n        text:\n          type: string\n          description: The text to be embedded\n        model:\n          type: string\n          description: The embedding model to use (e.g., \"bert-base-uncased\")\n\n    EmbeddingResponse:\n      description: Output from the text embedding function\n      properties:\n        embedding:\n          type: array\n          items:\n            type: number\n            format: float\n          description: The resulting embedding vector\n        dimensions:\n          type: integer\n          description: The number of dimensions in the embedding\n```\n\nHere is a previously inferred analysis from the fine tuning information above, in case its helpful: \n\n# Analysis of Agentic LLM System Utility\n\n## Key Strengths\n\n### Flexibility and Adaptability\n\n1. **Dynamic code generation**: AI agents can \"lookup\" and generate code based\n   on high-level descriptions, enabling on-demand functionality creation.\n2. **Cross-language support**: While Go is used in the example, the schema-based\n   approach suggests multi-language compatibility.\n\n### Standardization and Integration\n\n3. **Standardized schema**: XTP Schema provides a structured way to define\n   functions, inputs, and outputs, facilitating easier integration and\n   interoperability.\n\n### Performance Optimization\n\n4. **GPU acceleration**: Support for GPU-accelerated ML inference and text\n   embedding improves performance for AI-related tasks.\n5. **WASM compatibility**: Ability to compile to WebAssembly allows for\n   portable, high-performance code across various environments.\n\n### Development Efficiency\n\n6. **Code generation assistance**: AI-assisted code completion and boilerplate\n   generation speed up development.\n7. **Easy testing**: Simple command-line tools for testing implemented functions\n   streamline development and debugging.\n\n### Extensibility\n\n8. **Plugin architecture**: Allows easy addition of new functionalities without\n   core system modifications.\n\n## Overall Assessment\n\nThis system offers a powerful toolkit for developers working on AI-driven\napplications. It combines LLM flexibility with compiled code structure and\nefficiency, potentially accelerating complex AI system development while\nmaintaining robustness.\n\n## Potential Challenges\n\n- Learning curve associated with XTP Schema\n- Ensuring generated code meets performance and security standards\n\nDespite these challenges, the benefits in rapid prototyping and AI-powered\nfunctionality development appear to outweigh the potential hurdles.\n"
